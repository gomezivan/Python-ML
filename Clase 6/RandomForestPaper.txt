Existen diversos algoritmos de clasificación los cuales son usados para modelar modelos predictivos del mundo real, el problema que enfrenta un analista o científico de datos, es cual de ellos debe usar con el fin de brindar el mejor resultado posible. Ente los métodos de clasificación se pueden encontrar los métodos lineales que provienen de la estadística, los métodos de inteligencia artificial basados en reglas como los arboles de decisión, y por otra parte los métodos de ensamblajes, los cuales son una muy buena alternativa cuando se quiere tener un modelo que combine diferentes técnicas o algoritmos para el entrenamiento de los modelos en el caso de Machine Learning, es en este último escenario en donde aparece el método conocido como Random Forest, el cual es un método de ensamblaje de arboles que permite entrenar un conjunto de árboles de decisión de la más independiente y diferentes posibles para dar un único resultado o predicción. 
Esta técnica ha sido comparada contra 179 diferentes clasificadores con set de datos exactamente iguales y modelando el mismo problema. Encontrado que lo otros clasificadores experimentaron problemas de multicolinealidad, singularidad de covarianzas y otros errores causados por datos discretos, lo cual dio como resultado que el método Random Forest arrojó un mejor resultado promedio en el accuracy. 
