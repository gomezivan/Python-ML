{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "import category_encoders as ce\n",
    "import sys\n",
    "import os\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re  \n",
    "\n",
    "# BinEncoder = joblib.load('BinEncoder.pkl') \n",
    "clf = joblib.load('RF_generos2.pkl')\n",
    "\n",
    "YearBinaryEnco = joblib.load('YearBinaryEnco.pkl')\n",
    "tfidf_plot = joblib.load('tfidf_plot.pkl')\n",
    "tfidf_title = joblib.load('tfidf_title.pkl')\n",
    "\n",
    "\n",
    "def clasff_movie(title, plot, year):\n",
    "    \n",
    "    \n",
    "    #Preprocess\n",
    "    title_clean = text_clean(title, remove_stop_words=False)\n",
    "    plot_clean  = text_clean(plot)\n",
    "    \n",
    "    #Transform\n",
    "    YearBinary = YearBinaryEnco.transform(pd.DataFrame([year],columns=[\"year\"]))\n",
    "    title_tfidf_dtm = tfidf_title.transform(pd.Series([title_clean]))\n",
    "    title_feat_tfidf = pd.DataFrame(title_tfidf_dtm.toarray(), columns=tfidf_title.get_feature_names())\n",
    "\n",
    "    plot_tfidf_dtm = tfidf_plot.transform(pd.Series([plot_clean]))\n",
    "    plot_feat_tfidf = pd.DataFrame(plot_tfidf_dtm.toarray(), columns=tfidf_plot.get_feature_names())\n",
    "\n",
    "    #Create a dataframe \n",
    "    df_ = pd.concat([title_feat_tfidf, \n",
    "                  plot_feat_tfidf, \n",
    "                  YearBinary], axis=1) \n",
    "    \n",
    "    #Predict\n",
    "    predict_ = clf.predict_proba(df_)\n",
    "\n",
    "    return predict_\n",
    "\n",
    "\n",
    "# This function transform the text in order get ready data, remove stop words, stimming, Lemmatisation and n_grams\n",
    "def text_clean(text, remove_stop_words=True):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    document = text\n",
    "    \n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', document)\n",
    "\n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    #Removing punctuation\n",
    "    document = re.sub(r'[^\\w\\s]', '', document)\n",
    "\n",
    "    #LowerCase    \n",
    "    document = document.lower()\n",
    "    \n",
    "    #Split document word a word\n",
    "    words_document = text.split()\n",
    "    \n",
    "    #Remove clean_words\n",
    "    words_document = [word for word in words_document if word not in waste_words]\n",
    "    #Remove stop words\n",
    "    if remove_stop_words:\n",
    "        words_document = [word for word in words_document if word not in custom_stopwords]\n",
    "    \n",
    "    #stimming\n",
    "    words_document = [stemmer.stem(word) for word in words_document]\n",
    "    \n",
    "    #Lemmatisation\n",
    "    words_document = [wordnet_lemmatizer.lemmatize(word) for word in words_document]\n",
    "    words_document = [wordnet_lemmatizer.lemmatize(word, pos='v') for word in words_document]\n",
    "           \n",
    "    return ' '.join(words_document)\n",
    "\n",
    "custom_stopwords =['a', 'about', 'above', 'across', 'after', 'afterwards', 'again',\n",
    "       'against', 'ain', 'all', 'almost', 'alone', 'along', 'already',\n",
    "       'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst',\n",
    "       'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone',\n",
    "       'anything', 'anyway', 'anywhere', 'are', 'aren', \"aren't\",\n",
    "       'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become',\n",
    "       'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind',\n",
    "       'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill',\n",
    "       'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant',\n",
    "       'co', 'con', 'could', 'couldn', \"couldn't\", 'couldnt', 'cry', 'd',\n",
    "       'de', 'describe', 'detail', 'did', 'didn', \"didn't\", 'do', 'does',\n",
    "       'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'done', 'down', 'due',\n",
    "       'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else',\n",
    "       'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every',\n",
    "       'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen',\n",
    "       'fifty', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former',\n",
    "       'formerly', 'forty', 'found', 'four', 'from', 'front', 'full',\n",
    "       'further', 'get', 'give', 'go', 'had', 'hadn', \"hadn't\", 'has',\n",
    "       'hasn', \"hasn't\", 'hasnt', 'have', 'haven', \"haven't\", 'having',\n",
    "       'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein',\n",
    "       'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how',\n",
    "       'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed',\n",
    "       'interest', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its',\n",
    "       'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least',\n",
    "       'less', 'll', 'ltd', 'm', 'ma', 'made', 'many', 'may', 'me',\n",
    "       'meanwhile', 'might', 'mightn', \"mightn't\", 'mill', 'mine', 'more',\n",
    "       'moreover', 'most', 'mostly', 'move', 'much', 'must', 'mustn',\n",
    "       \"mustn't\", 'my', 'myself', 'name', 'namely', 'needn', \"needn't\",\n",
    "       'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody',\n",
    "       'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'o',\n",
    "       'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or',\n",
    "       'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out',\n",
    "       'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'rather',\n",
    "       're', 's', 'same', 'see', 'seem', 'seemed', 'seeming', 'seems',\n",
    "       'serious', 'several', 'shan', \"shan't\", 'she', \"she's\", 'should',\n",
    "       \"should've\", 'shouldn', \"shouldn't\", 'show', 'side', 'since',\n",
    "       'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone',\n",
    "       'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such',\n",
    "       'system', 't', 'take', 'ten', 'than', 'that', \"that'll\", 'the',\n",
    "       'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there',\n",
    "       'thereafter', 'thereby', 'therefore', 'therein', 'thereupon',\n",
    "       'these', 'they', 'thick', 'thin', 'third', 'this', 'those',\n",
    "       'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to',\n",
    "       'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty',\n",
    "       'two', 'un', 'under', 'until', 'up', 'upon', 'us', 've', 'very',\n",
    "       'via', 'was', 'wasn', \"wasn't\", 'we', 'well', 'were', 'weren',\n",
    "       \"weren't\", 'what', 'whatever', 'when', 'whence', 'whenever',\n",
    "       'where', 'whereafter', 'whereas', 'whereby', 'wherein',\n",
    "       'whereupon', 'wherever', 'whether', 'which', 'while', 'whither',\n",
    "       'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with',\n",
    "       'within', 'without', 'won', \"won't\", 'would', 'wouldn', \"wouldn't\",\n",
    "       'y', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your',\n",
    "       'yours', 'yourself', 'yourselves']\n",
    "\n",
    "waste_words =['!',\n",
    " '\"',\n",
    " '$',\n",
    " '%',\n",
    " '&',\n",
    " \"'\",\n",
    " '(',\n",
    " ')',\n",
    " ',',\n",
    " '-',\n",
    " '.',\n",
    " '/',\n",
    " ':',\n",
    " ';',\n",
    " '=',\n",
    " '?',\n",
    " 'a$$',\n",
    " 'a&m',\n",
    " 'aa',\n",
    " 'aaa',\n",
    " 'aam',\n",
    " '+',\n",
    " 'aang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess\n",
    "title_clean = text_clean(\"A Woman's Face\", remove_stop_words=False)\n",
    "plot_clean  = text_clean(\"in sweden ,  a female blackmailer with a disfiguring facial scar meets a gentleman who lives beyond his means .  they become accomplices in blackmail ,  and she falls in love with him ,  bitterly resigned to the impossibility of his returning her affection .  her life changes when one of her victims proves to be the wife of a plastic surgeon ,  who catches her in his apartment ,  but believes her to be a jewel thief rather than a blackmailer .  he offers her the chance to look like a normal woman again ,  and she accepts ,  despite the agony of multiple operations .  meanwhile ,  her gentleman accomplice forms an evil scheme to rid himself of the one person who stands in his way to a fortune  -  his four - year - old - nephew .\")\n",
    "year=\"2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_feat_tfidf: (1, 4172)\n",
      "plot_feat_tfidf: (1, 8951)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 13131)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Transform\n",
    "YearBinary = YearBinaryEnco.transform(pd.DataFrame([year],columns=[\"year\"]))\n",
    "title_tfidf_dtm = tfidf_title.transform(pd.Series([title_clean]))\n",
    "title_feat_tfidf = pd.DataFrame(title_tfidf_dtm.toarray(), columns=tfidf_title.get_feature_names())\n",
    "print(\"title_feat_tfidf: \" + str(title_feat_tfidf.shape))\n",
    "\n",
    "plot_tfidf_dtm = tfidf_plot.transform(pd.Series([plot_clean]))\n",
    "plot_feat_tfidf = pd.DataFrame(plot_tfidf_dtm.toarray(), columns=tfidf_plot.get_feature_names())\n",
    "print(\"plot_feat_tfidf: \" + str(plot_feat_tfidf.shape))\n",
    "\n",
    "#Create a dataframe \n",
    "df_ = pd.concat([plot_feat_tfidf.add_suffix('_1'), \n",
    "                      title_feat_tfidf.add_suffix('_2'), \n",
    "                      YearBinary], axis=1) \n",
    "\n",
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_0</th>\n",
       "      <th>year_1</th>\n",
       "      <th>year_2</th>\n",
       "      <th>year_3</th>\n",
       "      <th>year_4</th>\n",
       "      <th>year_5</th>\n",
       "      <th>year_6</th>\n",
       "      <th>year_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_0  year_1  year_2  year_3  year_4  year_5  year_6  year_7\n",
       "0       0       0       0       1       1       1       1       0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ye = \"2006\"\n",
    "df = pd.DataFrame([ye],columns=[\"year\"])\n",
    "df\n",
    "YearBinary = YearBinaryEnco.transform(df)\n",
    "YearBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13020362, 0.17560571, 0.10731402, 0.11716939, 0.31402017,\n",
       "        0.13158499, 0.14782341, 0.43374948, 0.13574491, 0.09581885,\n",
       "        0.04761875, 0.10992976, 0.12649445, 0.09018483, 0.07469877,\n",
       "        0.06921122, 0.04086857, 0.19386311, 0.06069164, 0.05780504,\n",
       "        0.06417878, 0.18054495, 0.04686146, 0.06250829]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasff_movie(\"A Woman's Face\", \n",
    "             \"in sweden ,  a female blackmailer with a disfiguring facial scar meets a gentleman who lives beyond his means .  they become accomplices in blackmail ,  and she falls in love with him ,  bitterly resigned to the impossibility of his returning her affection .  her life changes when one of her victims proves to be the wife of a plastic surgeon ,  who catches her in his apartment ,  but believes her to be a jewel thief rather than a blackmailer .  he offers her the chance to look like a normal woman again ,  and she accepts ,  despite the agony of multiple operations .  meanwhile ,  her gentleman accomplice forms an evil scheme to rid himself of the one person who stands in his way to a fortune  -  his four - year - old - nephew .\"\n",
    "             ,\"1941\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:8889/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [21/Apr/2019 16:58:42] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Apr/2019 16:58:42] \"GET /swagger.json HTTP/1.1\" 200 -\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "C:\\Users\\ivandario.gomez\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py:154: UserWarning: Loky-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "127.0.0.1 - - [21/Apr/2019 16:59:13] \"GET /Classification/?Title=Narrow%20Margin&Plot=in%20los%20angeles%20%2C%20%20the%20editor%20of%20a%20publishing%20house%20carol%20hunnicut%20goes%20to%20a%20blind%20date%20with%20the%20lawyer%20michael%20tarlow%20%2C%20%20who%20has%20embezzled%20the%20powerful%20mobster%20leo%20watts%20.%20%20carol%20accidentally%20witnesses%20the%20murder%20of%20michel%20by%20leo%20%27%20s%20hitman%20.%20%20the%20scared%20carol%20sneaks%20out%20of%20michael%20%27%20s%20room%20and%20hides%20in%20an%20isolated%20cabin%20in%20canada%20.%20%20meanwhile%20the%20deputy%20district%20attorney%20robert%20caulfield%20and%20sgt%20.%20%20dominick%20benti%20discover%20that%20carol%20is%20a%20witness%20of%20the%20murder%20and%20they%20report%20the%20information%20to%20caulfield%20%27%20s%20chief%20martin%20larner%20and%20they%20head%20by%20helicopter%20to%20canada%20to%20convince%20carol%20to%20testify%20against%20leo%20.%20%20however%20they%20are%20followed%20and%20the%20pilot%20and%20benti%20are%20murdered%20by%20the%20mafia%20.%20%20caulfield%20and%20carol%20flees%20and%20they%20take%20a%20train%20to%20vancouver%20.%20%20caulfield%20hides%20carol%20in%20his%20cabin%20and%20he%20discloses%20that%20there%20are%20three%20hitman%20in%20the%20train%20trying%20to%20find%20carol%20and%20kill%20her%20.%20%20but%20they%20do%20not%20know%20her%20and%20caulfield%20does%20not%20know%20who%20might%20be%20the%20third%20killer%20from%20the%20mafia%20and%20who%20has%20betrayed%20him%20in%20his%20office%20.&Year=1990 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "from flask import Flask\n",
    "from flask_restplus import Api, Resource, fields\n",
    "from sklearn.externals import joblib\n",
    "from Model_Movie_CLF import clasff_movie\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='Movie Genre Classification',\n",
    "    description='Desarrollado por: Iván Gómez, Cristian Najera, Natalia Martínez')\n",
    "\n",
    "ns = api.namespace('Classification', \n",
    "     description='Classification movie')\n",
    "   \n",
    "parser = api.parser()\n",
    "\n",
    "parser.add_argument(\n",
    "    'Title', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Title of the movie', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Plot', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Description of the movie', \n",
    "    location='args')\n",
    "\n",
    "parser.add_argument(\n",
    "    'Year', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Year of the movie', \n",
    "    location='args')\n",
    "\n",
    "\n",
    "resource_fields = api.model('Resource', {\n",
    "    'result': fields.String,\n",
    "})\n",
    "\n",
    "@ns.route('/')\n",
    "class PredPriceApi(Resource):\n",
    "\n",
    "    @api.doc(parser=parser)\n",
    "    @api.marshal_with(resource_fields)\n",
    "    def get(self):\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        return {\n",
    "         \"result\": clasff_movie(args['Title'],args['Plot'],args['Year'])\n",
    "        }, 200\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False, host='0.0.0.0', port=8889)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
